---
title: "Software standards"
format: html
---

## Framework for evaluating software standards in *Plasmodium* genomics

PGEforge aims to foster an ecosystem of high-quality, user-friendly tools that can be seamlessly integrated into genomic analysis workflows. One of the biggest challenges is the XXXX. 

Working towards this goal, a robust software standards evaluation framework was formulated to guide the development and assessment of tools used in *Plasmodium* genomic data analysis. This framework is crucial in addressing the variability and challenges associated with existing software tools but also to guide development of new tools, ensuring that they meet high standards of usability, accessibility, and reliability. This framework not only helps in maintaining consistency and reliability across different tools but also promotes best practices in software development, contributing to the overall advancement of tools for malaria genomic research.

### 'Ideal' software practices
One of the primary objectives of this framework is to define ‘ideal’ software practices that are not tool-specific but applicable across a range of genomic analysis tools. These practices encompass:

- Comprehensive documentation
- Ease of installation
- Compatibility across different operating systems
- Standardization of data input formats 

### Evaluation criteria 
To implement these standards, PGEforge has developed a set of measurable criteria that can be applied to evaluate the performance and usability of various tools. These criteria include:

- Quality and comprehensiveness of documentation
- Simplicity of installation processes
- Robustness of the tools in handling different data formats

Tools that meet these criteria are prioritized for comprehensive resource development (see the [Tutorial section](website_docs/tutorials_overview.qmd)), ensuring they are well-documented and easy to install and use.

### Tool evaluation


### Future work: tool benchmarking
Future work will focus on formal benchmarking, including the use of [canonical simulated and empirical datasets](website_docs/data_description.qmd) to evaluate the accuracy, sensitivity, and specificity of the tools in producing desired outcomes. By systematically benchmarking tools against known datasets, we can ensure that the tools not only meet theoretical standards but also perform reliably in practical applications. We will host these types of benchmarking in PGEforge in the near future.